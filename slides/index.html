<!DOCTYPE html>
<html>
  <head>
    <title>Assessing Amazon Turker and automated machine forecasts in the Hybrid Forecasting Competition</title>
    <meta charset="utf-8">
    <meta name="author" content="Andreas Beger, Predictive Heuristics" />
    <meta name="date" content="2018-12-13" />
    <link href="index_files/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link href="index_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="index_files/font-awesome-5.3.1/css/fontawesome-all.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom_theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Assessing Amazon Turker and automated machine forecasts in the Hybrid Forecasting Competition
### Andreas Beger, Predictive Heuristics
### 13 Dec 2018

---




&lt;!-- https://apreshill.github.io/data-vis-labs-2018/slides/06-slides_xaringan.html#13 --&gt;

class: middle

# Disclaimer

This research is based upon work supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via 2017-17071900005. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.


---
class: center, middle, inverse

# Hybrid Forecasting Competition (HFC)

---

# Project goal

&gt;The HFC program is developing and testing hybrid geopolitical forecasting systems. These systems integrate human and machine forecasting components to create maximally accurate, flexible, and scalable forecasting capabilities.
&gt;
&gt;Human-generated forecasts may be subject to cognitive biases and/or scalability limits. Machine-generated (i.e., statistical, computational) forecasting approaches may be more scalable and data-driven, but are often ill-suited to render forecasts for idiosyncratic or newly emerging geopolitical issues. Hybrid approaches hold promise for combining the strengths of these two approaches while mitigating their individual weaknesses.
&gt;
&gt;Performers are developing systems that integrate human and machine forecasting contributions in novel ways. These systems are competing in a multi-year competition to identify approaches that may enable the Intelligence Community (IC) to radically improve the accuracy and timeliness of geopolitical forecasts.

.small[From https://www.hybridforecasting.com]


---
background-image: url('img/screenshot-splash.png')
background-size: contain


---
background-image: url('img/screenshot-question.png')
background-size: contain


---

# Scoring

Multinomial Brier score:

`$$mBS = \sum_{i=1}^R(f_i - o_i)^2$$`

- `\(R\)` is the number of answer options, `\(f\)` the vector of weights summing to 1, and `\(o\)` a 0/1 vector marking the correct option
- ranges from 0 (good) to 2 (bad)

--

Ordered Brier score: 

1. Split the ordinal categories (A-B-C-D) into cumulative binary pairs, aggregating the forecast probabilities for each grouping of categories (A-BCD; AB-CD; ABC-D). 
2. Calculate the multinomial Brier score for each of the binary categories.
3. Average across the binary category scores to obtain the final Brier score. 

- also ranges from 0 to 2
- "near misses" are penalized less than far misses


---
class: center, middle, inverse

# The Hybrid part:

# Some users could see time series charts and machine forecasts for some IFPs


---

# How this works

- dig


---

# Data

- RCT-A, the first trial period, lasted from 7 March to 7 September 2018
- Use subset of forecasts from 2 May to 1 August 2018

N fcasts, n IFPs


---

# Summary of some findings in the paper

Volunteers are better forecasts than Amazon Turkers

Machines are somewhere in the middle

Human forecasters who saw the machine forecasts did poorly; volunteer forecasts who saw only charts had overall the best performance

It's not clear why though, e.g.:
- they outperformed on questions that did not have data (charts and model)
- they outperformed volunteer forecasters who saw the machine forecasts even when the machine forecasts had good accuracy

Relative performance: where did the machine forecasts do better than human forecasters?

---

Two models


---
class: center, middle

![:scale 80%](img/model-machine-by-data-source.png)


---

# ACLED 5-option


---

# OECD interest rates


---

# ACLED binary question


---

Machine forecasts did well on count questions that require data aggregation 

Some of the overall hardest questions, and where to some extent human forecasters did better, are economic/financial monthly series 

- OECD interest rates
- FAO food price indices


---
class: center, middle, inverse

# Thank you!

Register to forecast at: 
Internal platform: 

.left[
<i class="fas  fa-envelope "></i>: [adbeger@gmail.com](mailto:adbeger@gmail.com)

<i class="fab  fa-github-square "></i>: https://github.com/andybega/asia-polmeth-2019

<i class="fas  fa-file "></i>: [link to paper (on github under docs/)](https://github.com/andybega/asia-polmeth-2019/blob/master/docs/BegerWard_HFC_AsiaPolmeth2019.pdf)

<i class="fab  fa-slideshare "></i>: [slide source](https://github.com/andybega/asia-polmeth-2019/tree/master/slides)
]
    </textarea>
<script src="libs/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create();
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
